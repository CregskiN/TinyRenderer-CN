# Lesson 6: 软渲染器的着色器

| 作者 | [ssloy](https://github.com/ssloy)       |
| ---- | --------------------------------------- |
| 翻译 | [CregskiN](https://github.com/CregskiN) |
| 校对 | 未校对                                  |

**再次提示：我把源代码放在这里是为了和你的比较，不要用我的代码，你得自己写。我是一个糟糕的程序员，请写一个最疯狂的着色器，然后发给我，我会展示到这里。**



有意思的来了！首先，检查一下当前[源代码](https://github.com/ssloy/tinyrenderer/tree/f037c7a0517a632c7391b35131f9746a8f8bb235)的内容：

-   geometry.cpp+.h — 218 lines
-   model.cpp+.h — 139 lines
-   our_gl.cpp+.h — 102 lines
-   main.cpp — 66 lines

共 525 行，如我所想。请注意，负责渲染是 out_gl.* 文件，以及 main.cpp 中共 168 行的代码。

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/e3cd704925f52b5466ab3c4f9fbab899.png) 



# 重构源代码

main.cpp 已经变得过于冗杂了，让我们把它拆分成两部分：

+ our_gl.cpp + h ：这部分程序员不能动，粗糙的说，这是 OpenGL 库的二进制文件
+ main.cpp ：这部分我们可以为所欲为

那么，我会往 our_gl 中加些什么？ModelView、Viewport、Projection 的初始化函数，以及 triangle 光栅化函数。就这些！

```c++
#include "tgaimage.h"
#include "geometry.h"

extern Matrix ModelView;
extern Matrix Viewport;
extern Matrix Projection;

void viewport(int x, int y, int w, int h);
void projection(float coeff=0.f); // coeff = -1/c
void lookat(Vec3f eye, Vec3f center, Vec3f up);

struct IShader {
    virtual ~IShader();
    virtual Vec3i vertex(int iface, int nthvert) = 0;
    virtual bool fragment(Vec3f bar, TGAColor &color) = 0;
};

void triangle(Vec4f *pts, IShader &shader, TGAImage &image, TGAImage &zbuffer);
```

main.cpp 文件只有 66 行，因此我列出了所有内容 (抱歉代码很长，但我喜欢完整的它)：

```c++
#include <vector>
#include <iostream>

#include "tgaimage.h"
#include "model.h"
#include "geometry.h"
#include "our_gl.h"

Model *model     = NULL;
const int width  = 800;
const int height = 800;

Vec3f light_dir(1,1,1);
Vec3f       eye(1,1,3);
Vec3f    center(0,0,0);
Vec3f        up(0,1,0);

struct GouraudShader : public IShader {
    Vec3f varying_intensity; // written by vertex shader, read by fragment shader

    virtual Vec4f vertex(int iface, int nthvert) {
        varying_intensity[nthvert] = std::max(0.f, model->normal(iface, nthvert)*light_dir); // get diffuse lighting intensity
        Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); // read the vertex from .obj file
        return Viewport*Projection*ModelView*gl_Vertex; // transform it to screen coordinates
    }

    virtual bool fragment(Vec3f bar, TGAColor &color) {
        float intensity = varying_intensity*bar;   // interpolate intensity for the current pixel
        color = TGAColor(255, 255, 255)*intensity; // well duh
        return false;                              // no, we do not discard this pixel
    }
};

int main(int argc, char** argv) {
    if (2==argc) {
        model = new Model(argv[1]);
    } else {
        model = new Model("obj/african_head.obj");
    }

    lookat(eye, center, up);
    viewport(width/8, height/8, width*3/4, height*3/4);
    projection(-1.f/(eye-center).norm());
    light_dir.normalize();

    TGAImage image  (width, height, TGAImage::RGB);
    TGAImage zbuffer(width, height, TGAImage::GRAYSCALE);

    GouraudShader shader;
    for (int i=0; i<model->nfaces(); i++) {
        Vec4f screen_coords[3];
        for (int j=0; j<3; j++) {
            screen_coords[j] = shader.vertex(i, j);
        }
        triangle(screen_coords, shader, image, zbuffer);
    }

    image.  flip_vertically(); // to place the origin in the bottom left corner of the image
    zbuffer.flip_vertically();
    image.  write_tga_file("output.tga");
    zbuffer.write_tga_file("zbuffer.tga");

    delete model;
    return 0;
}
```

来看看它是如何工作的。跳转到头文件，我们定义了一些全局常量：screen、dimensions、camera positions 等等。我会在下一节解释 GouraudShader，所以先跳过。接着，就是 main() 函数：

+ 解析 .obj 文件
+ 初始化 ModelView，Projection，以及 Viewport 矩阵(回忆一下，这些矩阵的实例其实在 our_gl 模块)
+ 遍历模型中所有的三角形，并依次光栅化

最后一步才是最有意思的，外循环遍历所有三角形，内循环遍历当前三角形的所有顶点，并对每个顶点调用顶点着色器(vertex shader)。

**顶点着色器的主要目的，是变换顶点的坐标系。第二个目的，是为片段着色器(fragment shader) 准备数据。**

那之后呢？按照惯例光栅化。意外地是，在光栅化中发生了什么，我们不知道(把它写出来不就知道了！)。光栅化时，对每个像素调用的，叫做片段着色器 (fragement sahder)。

**片段着色器的主要目的，是决定当前像素的颜色。其次，我们可以通过返回 true 丢弃当前的像素。**

OpenGL 2 的渲染管线能表明这个过程 (实际上，新版本也或多或少和这个一样)：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/OpenGL-2.0-Programmable-Shader-Pipeline.png) 

由于课时限制，我只关注 OpenGL 2，也因此这里只有片段着色器和顶点着色器。在更新版本的 OpenGL 中还能使用其他着色器，就比如几何着色器 (Geometry shader) 允许动态生成几何体。

好的，在上图中，我们没有涉及的部分用蓝色表示，其余用橙色表示。实际上，我们的 main() 函数就是图元处理阶段 (Primitive processing)，被称为顶点着色器。这没有图元装配 (Primitive Assembly)，因为在这我们只用绘制三角形 (在我们的代码中，这部分与图元处理阶段合并了)。triangle() 函数就是光栅化 (Rasterizer)，其内对三角形内每个像素调用片段着色器 (fragment shader)，然后执行深度检查 (z-buffer) 等。

这就是全部了。你知道着色器是什么，接下来创建你的着色器吧。



# 展示我用 Gouraud Shading 实现的着色器

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/output.png) 

来查看一下我列出的 main.cpp 中着色器的部分。顾名思义，就是 Gouraud shader，来看看代码：

```c++
Vec3f varying_intensity; // 由顶点着色器写入，片段着色器读取
virtual Vec4f vertex(int iface, int nthvert) {
  // 得到漫反射强度
  varying_intensity[nthvert] = std::max(0.f, model->normal(iface, nthvert)*light_dir); 
	// 从 .obj 文件中读取模型
  Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); 
	// 变换到屏幕坐标系
  return Viewport*Projection*ModelView*gl_Vertex; 
}
```

**varying** 是 GLSL 语言中保留的关键字，我用 varying_intensity 当变量名以显示对应关系 (在[lesson 9](https://github.com/ssloy/tinyrenderer/wiki/Lesson-9:-Real-OpenGL-(GLSL)-application)中我们会讨论 GLSL)。在 varying 变量中，我们存储要在三角形内用于插值的数据，随后片段着色器计算出插值 (当前像素的相关插值)。

看一下片段着色器中的代码：

```c++
  Vec3f varying_intensity;
// [...]
virtual bool fragment(Vec3f bar, TGAColor &color) {
  float intensity = varying_intensity*bar;   // 插值获取当前像素的 intensity
  color = TGAColor(255, 255, 255)*intensity; // well duh
  return false;                              // 返回 false，表示我们没有丢弃当前像素
}
```

这发生每个三角形内像素的绘制过程中；它接收[重心坐标](https://en.wikipedia.org/wiki/Barycentric_coordinate_system)，以插值获取 varying_ 数据的值，因此，intiensity 的值可以这样计算：varying_intensity[0]\*bar[0] + varying_intensity[1]\*bar[1] + varying_intensity[2]\*bar[2]。又或者用两个向量点乘获取：varying_intensity*bar。在真正的 GLSL 中，片段着色器接收准备好的、已经插值完毕的值。

注意，shader 返回一个 bool 值，如果了解光栅化 (our_gl.cpp, triangle() 函数) 中发生了什么，就不难理解这样的设计：

```c++
TGAColor color;
bool discard = shader.fragment(c, color);
if (!discard) {
    zbuffer.set(P.x, P.y, TGAColor(P.z));
    image.set(P.x, P.y, color);
}
```

片段着色器能放弃绘制当前像素，那对该像素的光栅化就跳过了。如果你想创建二进制遮罩，或者其他什么东西 ([lesson 9](https://github.com/ssloy/tinyrenderer/wiki/Lesson-9:-Real-OpenGL-(GLSL)-application)中有一个非常酷的丢弃像素的例子)。

当然，光栅化器不能获悉所有你编写的奇怪的东西，也因此不能和你的着色器一起预编译。这部分，我用了一个抽象类 IShader 衔接这两个着色器。哇，我很少用抽象类，但没有它我们会很痛苦。指向函数的指针很难看。



# 对着色器的第一处改动

```c++
virtual bool fragment(Vec3f bar, TGAColor &color) {
    float intensity = varying_intensity*bar;
    if (intensity>.85) intensity = 1;
    else if (intensity>.60) intensity = .80;
    else if (intensity>.45) intensity = .60;
    else if (intensity>.30) intensity = .45;
    else if (intensity>.15) intensity = .30;
    else intensity = 0;
    color = TGAColor(255, 155, 0)*intensity;
    return false;
}
```

简单改动 Gouraud shading，允许有六个光强值，这里是最终效果：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/f2bf83c5994b9051aaba499cb05e65bf.png) 



# 纹理

我会跳过 [Phong shading](https://en.wikipedia.org/wiki/Phong_shading)，但请看一眼这篇文章。还记得我布置的纹理家庭作业吗？我们必须插值 uv 坐标，因此，我创建了一个 2x3 矩阵，两行分别表示 (每个像素的) uv 坐标。

```c++
struct Shader : public IShader {
  Vec3f varying_intensity; // written by vertex shader, read by fragment shader
  mat<2,3,float> varying_uv;        // same as above

  virtual Vec4f vertex(int iface, int nthvert) {
    varying_uv.set_col(nthvert, model->uv(iface, nthvert));
    varying_intensity[nthvert] = std::max(0.f, model->normal(iface, nthvert)*light_dir); // 获取漫反射光强
    Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); // 从 .obj 文件中读取模型
    return Viewport*Projection*ModelView*gl_Vertex; // 转换到屏幕坐标系
  }

  virtual bool fragment(Vec3f bar, TGAColor &color) {
    float intensity = varying_intensity*bar;   // 插值获取当前像素光强
    Vec2f uv = varying_uv*bar;                 // 插值获取当前像素 uv 坐标
    color = model->diffuse(uv)*intensity;      // well duh
    return false;                              // no, we do not discard this pixel
  }
};
```

结果在这里：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/51f723ffe99f4c6888a13091796da8f7.png) 



# 法线映射 Normal Mapping

目前，我们有了纹理坐标。我们可以在纹理图像中存储什么内容呢？啥都能存。存储内容可以是颜色、方向、温度等等。来下载这张纹理：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/african_head_nm.png) 

如果把图像的 RGB 值解释为 xyz 方向 ，这个图像就能表示出**每个像素的**法向量，而不仅仅是之前顶点坐标的法向量。

​		另外，将这个图像与另一个比较，会发现它们包含相同的信息，但在另一帧中 (frame)：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/african_head_nm_tangent.png) 

第一幅图像给出了全局笛卡尔坐标系下的法向量，第二幅给出的是 [Darboux frame](https://en.wikipedia.org/wiki/Darboux_frame) 下的法向量。在 Darboux frame 中，z 向量垂直于物体，x 是主曲率方向，y 是它们俩的叉积。

**练习 1**：你能说出哪副图表示 Darboux frame，哪副图表示全局坐标系吗？

**练习 2**：你能否说出哪张表示得更高，为啥吗？

```c++
struct Shader : public IShader {
    mat<2,3,float> varying_uv;  // same as above
    mat<4,4,float> uniform_M;   //  Projection*ModelView
    mat<4,4,float> uniform_MIT; // (Projection*ModelView).invert_transpose()

    virtual Vec4f vertex(int iface, int nthvert) {
        varying_uv.set_col(nthvert, model->uv(iface, nthvert));
        Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); // read the vertex from .obj file
        return Viewport*Projection*ModelView*gl_Vertex; // transform it to screen coordinates
   }

    virtual bool fragment(Vec3f bar, TGAColor &color) {
        Vec2f uv = varying_uv*bar;                 // interpolate uv for the current pixel
        Vec3f n = proj<3>(uniform_MIT*embed<4>(model->normal(uv))).normalize();
        Vec3f l = proj<3>(uniform_M  *embed<4>(light_dir        )).normalize();
        float intensity = std::max(0.f, n*l);
        color = model->diffuse(uv)*intensity;      // well duh
        return false;                              // no, we do not discard this pixel
    }
};
[...]
    Shader shader;
    shader.uniform_M   =  Projection*ModelView;
    shader.uniform_MIT = (Projection*ModelView).invert_transpose();
    for (int i=0; i<model->nfaces(); i++) {
        Vec4f screen_coords[3];
        for (int j=0; j<3; j++) {
            screen_coords[j] = shader.vertex(i, j);
        }
        triangle(screen_coords, shader, image, zbuffer);
    }
```

**uniform** 是 GLSL 的保留字，用这个可以往着色器中传递常量数据。在这里，我传入了 Projection*ModelView，以及用于变换法向量的逆转置矩阵 ([lesson 5](https://github.com/ssloy/tinyrenderer/wiki/Lesson-5:-Moving-the-camera)末尾的内容)。所以，光照强度的计算与之前相同，只有一个例外：从法线映射纹理中获取法线，而不再是插值获取 (别忘了变换光线向量和法向量)。

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/161ecc7c4f0147ca8ae66f0eb21baf29.png) 



# 高光映射

好的，继续一些有意思的东西。计算机图形学是一门欺骗的艺术。为更好的戏弄你的眼睛，我们用光照模型中的 [Phong 近似(Phong's approximation)](https://en.wikipedia.org/wiki/Phong_reflection_model)。Phong 提出将最终光照效果看作三种光加权叠加的结果：环境光(ambient) (每个像素都有)，漫反射光(diffuse lighting) (到目前我们一直计算的)，以及高光(psecular lighting)。

下面的图能解释：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/e3720a5dfedc49edb0bf70f8bc64204a.png) 

假设光线在物体表面向任意方向均匀反射，我们计算法向量和光线方向向量夹角的余弦值，作为漫反射光。如果是有光泽(glossy)的表面呢？在极限情况下(镜面)，当且仅当我们能看到该像素反射的光源时，该像素才会被点亮：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/d58cd3bbab46463e87b782a12a147fbb.png) 

在漫反射光计算中，我们计算了法向量 **v** 和光源向量 **I** 夹角的余弦值，现在我们关注反射光方向 **r** 与观测方向 **v** 的夹角(余弦值)。

**练习 3**：已知向量 **n** 和 **l** ，求向量 **r** 

*答*：如果 **n** 和 **l** 已经标准化，那 **r** = 2**n**<**n**,**l**> - **l**

我们计算余弦值作为漫反射光的光强，但在有光泽的表面上，往一个方向反射的光比其他方向更多！那么，如果我取余弦值的十次方呢？回想一下，对小于 1 的数取的幂越高，数就会越小。对余弦值取十次方，同时也意味着反射光束半径会变得更小。如果是百次方，光束半径会更小！幂数存储在一个特殊的纹理(高光映射纹理)中，这个纹理能表明每个像素是否是有光泽的。

>   译者注：
>
>   这里解释一下光束反射半径 reflected beam radius 会变小的数学含义。假设原始夹角是 60 度，则 cosin 值为 1/2。如果在计算 cosin 值时加一个幂数 10，则得出的 cosin 值会变小。如果还想得到与之前接近的 cosin 值，就必须减小夹角。不准确地说，cosin 值表示在物体表面观测到的光强。

```c++
struct Shader : public IShader {
    mat<2,3,float> varying_uv;  // same as above
    mat<4,4,float> uniform_M;   //  Projection*ModelView
    mat<4,4,float> uniform_MIT; // (Projection*ModelView).invert_transpose()

    virtual Vec4f vertex(int iface, int nthvert) {
        varying_uv.set_col(nthvert, model->uv(iface, nthvert));
        Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); // read the vertex from .obj file
        return Viewport*Projection*ModelView*gl_Vertex; // transform it to screen coordinates
    }

    virtual bool fragment(Vec3f bar, TGAColor &color) {
        Vec2f uv = varying_uv*bar;
        Vec3f n = proj<3>(uniform_MIT*embed<4>(model->normal(uv))).normalize();
        Vec3f l = proj<3>(uniform_M  *embed<4>(light_dir        )).normalize();
        Vec3f r = (n*(n*l*2.f) - l).normalize();   // reflected light
        float spec = pow(std::max(r.z, 0.0f), model->specular(uv));
        float diff = std::max(0.f, n*l);
        TGAColor c = model->diffuse(uv);
        color = c;
        for (int i=0; i<3; i++) color[i] = std::min<float>(5 + c[i]*(diff + .6*spec), 255);
        return false;
    }
};
```

我觉得无需在上边的代码添加任何注释了，除了系数：

```c++
for (int i=0; i<3; i++) color[i] = std::min<float>(5 + c[i]*(diff + .6*spec), 255);
```

我用 5 表示环境光分量，1 作为漫反射分量的权值，0.6 作为高光分量的权值。对于系数的选取，全在于你。不同的选择，在物体表面有不同的表现。这活通常是艺术家们干的。

*请注意：一般情况下三个系数的和必须为 1，可你知道，我喜欢亮一些的图像。*

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/5ac94044fb2b405f9b9c1647e5b86feb.png) 

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06-shaders/boggie.png) 



# 总结

我们知道了如何渲染漂亮的场景，但我们用的光照却很不真实。在下一篇文章，我会讨论阴影。

Enjoy！

