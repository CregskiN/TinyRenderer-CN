# Lesson 3: 隐藏面移除(z buffer)

| 作者 | [ssloy](https://github.com/ssloy)       |
| ---- | --------------------------------------- |
| 翻译 | [CregskiN](https://github.com/CregskiN) |
| 校对 | 未校对                                  |



# 介绍

​		早，让我为你介绍我的黑人朋友——z-buffer，他会帮我们丢弃上一节中隐藏面的视觉伪影。

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/3f057a75601d8ac34555e72ea03ef711.png)

​		这之前我想提一句，我在课程中反复使用的模型是用[Vidar Rapp](https://se.linkedin.com/in/vidarrapp)创建的，我已经拿到用于教学渲染基础的授权，而且我破坏了它，但我保证，由你来把眼睛还给这哥们儿。

​		那么回归正题，理论上我们能绘制出所有三角形而不丢弃任何一个。如果我们按从远到近渲染，近处的面会遮盖住远处的面，这就是[画家算法(painter's algorithm)](http://en.wikipedia.org/wiki/Painter's_algorithm)。不幸的是，这个算法需要极大的算力：每当摄像机移动一次，我们需要重排场景中所有元素(按远近)，而且场景还有可能是动态的......这甚至不是主要问题，主要问题是我们并不是永远都能得到正确的远近顺序。

# 设想一个简单的场景

​		设想一个由三个三角形组成的场景：摄像机从上往下观察，我们把具有颜色的三角形，投影到白色平面上：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/d493c52da4cabe9a057c26f696784956.png) 

渲染结果应该是这样的：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/023668cb8ea97f59bf87d982c1e8b030.png) 

​		蓝色面——是在红色面的前面还是后面？画家算法在这就行不通了，它很可能把蓝色面拆分成两部分 (一部分在红色面前面，一部分在后面)，而且，在红色面前面的部分，还要再拆分成两部分——一部分在绿色面前面，一部分在后面......你可能明白问题所在了：当一个场景中有数以百万计的三角形，算力消耗恐怖如斯，可能[BSP trees](https://en.wikipedia.org/wiki/Binary_space_partitioning)能解决这个问题。顺便提一句，BSP tree 是一种常用于移动的摄像机的数据结构，很复杂。唉，人生苦短。

# 简单点: 降一个维度，T-buffer

​		我们降一个维度，同时沿着黄色平面把上面的场景切割：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/d673f40bcadbe53f4b3cb29bbbcfb461.png)

​		我的意思是，现在我们的场景中有三条线段(即黄色面与每个三角形的交线)，最终渲染常规宽度，1 像素高度：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/3d4c4a1710b8e2558beb5c72ea52a61a.png)

​		一如往常，这个[commit](https://github.com/ssloy/tinyrenderer/tree/d9c4b14c0d8c385937bc87cee1178f1e42966b7c)也可以看看。我们的场景是二维的，所以很容易用第一节中的 line() 函数绘制。

```c++
{ // just dumping the 2d scene (yay we have enough dimensions!)
  TGAImage scene(width, height, TGAImage::RGB);

  // scene "2d mesh"
  line(Vec2i(20, 34),   Vec2i(744, 400), scene, red);
  line(Vec2i(120, 434), Vec2i(444, 400), scene, green);
  line(Vec2i(330, 463), Vec2i(594, 200), scene, blue);

  // screen line
  line(Vec2i(10, 10), Vec2i(790, 10), scene, white);

  scene.flip_vertically(); // i want to have the origin at the left bottom corner of the image
  scene.write_tga_file("scene.tga");
}
```

​		这就是我们 2D 场景的侧视图：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/20e9d8742d17979ec70e45cafacd63a5.png)

​		注意线段宽度是 1 像素，代码里为便于在高分辨率屏幕上观察，把图像高度设置为 16px。*rasterize()* 函数只往图像中第一行写入颜色。

```c++
TGAImage render(width, 16, TGAImage::RGB);
int ybuffer[width];
for (int i=0; i<width; i++) {
  ybuffer[i] = std::numeric_limits<int>::min();
}
rasterize(Vec2i(20, 34),   Vec2i(744, 400), render, red,   ybuffer);
rasterize(Vec2i(120, 434), Vec2i(444, 400), render, green, ybuffer);
rasterize(Vec2i(330, 463), Vec2i(594, 200), render, blue,  ybuffer);
```

​		我声明了一个具有维度的神奇数组 ybuffer，这个数组的元素均用最小整数初始化。随后我调用 *rasterize()* 函数，将这个数组、图像渲染对象作为参数传入。

```c++
void rasterize(Vec2i p0, Vec2i p1, TGAImage &image, TGAColor color, int ybuffer[]) {
    if (p0.x>p1.x) {
        std::swap(p0, p1);
    }
    for (int x=p0.x; x<=p1.x; x++) {
        float t = (x-p0.x)/(float)(p1.x-p0.x);
        int y = p0.y*(1.-t) + p1.y*t;
        if (ybuffer[x]<y) {
            ybuffer[x] = y;
            image.set(x, 0, color);
        }
    }
}
```

​		这相当的简单：我遍历 p0.x 和 p1.x 之间所有的 x 坐标，计算片段内相应的 y 坐标，然后检查当前 *ybuffer* 数组中 x 下标对应的元素。如果当前 y 值比 *ybuffer* 中 y 值更接近摄像机，那就把这个像素绘制到屏幕上，同时更新 *ybuffer*。

​		来瞧瞧一步步下来是什么样。在调用第一个 *rasterize()* ，绘制红色线段后，内存中是这样的：

屏幕：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/01694d604755b68c406998c03db374d9.png) 

ybuffer：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/65ddaf2b4d87f9b80127ecc6b02d0f72.png) 

​		洋红色代表最小整数值，这些位置对应着屏幕中我们没有接触的地方。其他部分以灰色显示：越亮表示离摄像机越近，越暗表示离摄像机越远。

​		然后，我们绘制绿色线段：

屏幕：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/6f081ac5fc77e2ec4bc733c945b16615.png) 

ybuffer：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/bae97132fc4ae67584b46b03d7350944.png) 

​		最后绘制那条蓝色的：

屏幕：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/d6fdb1d49161923ac91796967afa766e.png) 

ybuffer: ![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/8f430d7de76bdcbda73b8de2986fbe49.png) 

​		恭喜，我们刚刚在 1D 屏幕上绘制出了一个 2D 场景！再次欣赏一下渲染结果：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/24935d71a1b0023ee3cb48934fae175d.png) 

# 回到 3D

​		在 2D 屏幕上绘制，那 z-buffer 也必须是二维的：

```c++
int *zbuffer = new int[width*height];
```

​		个人而言，我喜欢把二维缓冲区抽象成一维的，转换很简单：

```c++
int idx = x + y*width;
```

​		逆转换：

```c++
int x = idx % width;
int y = idx / width;
```

​		在随后的代码中，我简单地遍历所有三角形，并且调用 rasterizer 函数，传入当前三角形、z-buffer 的引用。

​		唯一的难点，就是如何计算我们想绘制像素的 z 值，回想一下在之前的 y-buffer 中，我们是如何计算 y 值的：

```c++
int y = p0.y*(1.-t) + p1.y*t;
```

​		t 的本质是什么？(1-t, t) 是用线段端点 p0 p1 表示的点 (x, y) 的重心坐标：p0 * (1-t) + p1 * t。所以关键是获取用于三角形光栅化形式的重心坐标，然后用重心坐标乘三角形三个顶点的 z 值，计算出当前我们要绘制像素的 z 值：

> 译者注：这里的计算也被称作**插值**

```c++
triangle(screen_coords, float *zbuffer, image, TGAColor(intensity*255, intensity*255, intensity*255, 255));

[...]

void triangle(Vec3f *pts, float *zbuffer, TGAImage &image, TGAColor color) {
    Vec2f bboxmin( std::numeric_limits<float>::max(),  std::numeric_limits<float>::max());
    Vec2f bboxmax(-std::numeric_limits<float>::max(), -std::numeric_limits<float>::max());
    Vec2f clamp(image.get_width()-1, image.get_height()-1);
    for (int i=0; i<3; i++) {
        for (int j=0; j<2; j++) {
            bboxmin[j] = std::max(0.f,      std::min(bboxmin[j], pts[i][j]));
            bboxmax[j] = std::min(clamp[j], std::max(bboxmax[j], pts[i][j]));
        }
    }
    Vec3f P;
    for (P.x=bboxmin.x; P.x<=bboxmax.x; P.x++) {
        for (P.y=bboxmin.y; P.y<=bboxmax.y; P.y++) {
            Vec3f bc_screen  = barycentric(pts[0], pts[1], pts[2], P);
            if (bc_screen.x<0 || bc_screen.y<0 || bc_screen.z<0) continue;
            P.z = 0;
            for (int i=0; i<3; i++) P.z += pts[i][2]*bc_screen[i];
            if (zbuffer[int(P.x+P.y*width)]<P.z) {
                zbuffer[int(P.x+P.y*width)] = P.z;
                image.set(P.x, P.y, color);
            }
        }
    }
}
```

​		我们改动了如此少的代码，就把上一节中不可见的部分丢弃了：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/f93a1fc1cbaebb9c4670ae0003e62947.png)

​		源码在[这里](https://github.com/ssloy/tinyrenderer/tree/68a5ae382135d679891423fb5285fdd582ca389d)可以找到。

# 除了插值计算 z 值，我们还能做什么？

**纹理(texture)**！这是我们的家庭作业。

这部分是介绍 .obj 文件的格式，原文是

> In the .obj file we have lines starting with "vt u v", they give an array of texture coordinates. The number in the middle (between the slashes) in the facet lines "f x/x/x x/x/x x/x/x" are the texture coordinates of this vertex of this triangle. Interpolate it inside the triangle, multiply by the width-height of the texture image and you will get the color to put in your render.

.obj 文件格式很简单，译者这里说明一下：

+ `v -0.000581696 -0.734665 -0.623267` 

  v 即 vertex，表示这个顶点的 3D 坐标

+ `vt  0.897 0.370 0.000` 

  vt 即 vertex texture，表示一个纹理坐标 uvt，一般 3D 模型只需要 2D 纹理，故第三个分量一般是 0

+ `vn  0.617 0.401 0.678` 

  vn 即 vertex normal，表示一个顶点的法线，计算光照会用到

+ `f 106/83/106 107/84/107 108/85/108` 

  f 即 face，后跟的三组数字代表多边形的顶点，这里给出的是三个顶点，故为三角形。每组数字依次表示 位置v编号/纹理坐标vt编号/法线vn编号，编号即 v、vt、vn 在 obj 文件中的出现顺序，从 1 开始计

所谓**插值计算像素的 z 的某些属性**，可以这样理解：

> 假设像素 P 在三角形 ABC 内的重心坐标为 (a, b, 1-a-b)，则：
>
> + 像素 P 的法线 P.normal = A.normal*a + B.normal\*b + C.normal\*(1-a-b)
> + 像素 P 的颜色 P.color = A.color\*a + B.color\*b + C.normal\*(1-a-b)
> + 像素 P 的深度 P.z = A.z\*a + B.z\*b + C.z\*(1-a-b)
>
> 重心坐标的本质，就是描述三个顶点对三角形内每个 pixel 的“影响”。

漫反射贴图在[这里](https://github.com/ssloy/tinyrenderer/raw/master/obj/african_head/african_head_diffuse.tga)找到。

​		下边的例子，是我希望你们做出来的：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/03-zbuffer/73714966ad4a4377b8c4df60bef03777.png)



























