# Lesson 7: 阴影映射

| 作者 | [ssloy](https://github.com/ssloy)       |
| ---- | --------------------------------------- |
| 翻译 | [CregskiN](https://github.com/CregskiN) |
| 校对 | 未校对                                  |

# 目标

这门 CG 讲座的课程已经快结束了。今天的目的是计算阴影。**注意，我们讨论的是硬阴影 hard shadows，至于软阴影 soft shadows 那是另一回事。**一如既往，代码在[这里](https://github.com/ssloy/tinyrenderer/tree/0c1d955e4f86c25f31f97e4f4563313ddba0c104)。

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/07-shadows/50de2abe990efa345664f98c9464a4c8.png) 

# 问题陈述

到目前为止，通过简单的局部着色，局部均匀计算光线方向和法线，我们已经正确渲染出凸面物体。不幸的是，这种方法在非凸面物体上并不能得到正确的结果。下面是我们用之前的知识可以得到的图像：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/07-shadows/b4af24130ecb1536703e4793308af425.png) 

为什么有光线打在右肩，而我们却不能看到他左角的影子？这不好。

关键点很简单：我们会做两遍渲染。第一遍，我们会渲染当摄像机放到光源位置时的图像，如此就能判断出哪些部分可以被光线打到，哪些不可以。然后在第二遍渲染中，我们在考虑每个 fragment 可见性的情况下渲染。没什么困难。让我们用下面的 shader：

```c++
struct DepthShader : public IShader {
    mat<3,3,float> varying_tri;

    DepthShader() : varying_tri() {}

    virtual Vec4f vertex(int iface, int nthvert) {
        Vec4f gl_Vertex = embed<4>(model->vert(iface, nthvert)); // read the vertex from .obj file
        gl_Vertex = Viewport*Projection*ModelView*gl_Vertex;          // transform it to screen coordinates
        varying_tri.set_col(nthvert, proj<3>(gl_Vertex/gl_Vertex[3]));
        return gl_Vertex;
    }

    virtual bool fragment(Vec3f bar, TGAColor &color) {
        Vec3f p = varying_tri*bar;
        color = TGAColor(255, 255, 255)*(p.z/depth);
        return false;
    }
};
```

shader 简单地将 z-buffer 的数据复制到 framebaffer，下面是我如何在 main() 函数中调用它的：

```c++
{ // rendering the shadow buffer
    TGAImage depth(width, height, TGAImage::RGB);
    lookat(light_dir, center, up);
    viewport(width/8, height/8, width*3/4, height*3/4);
    projection(0);

    DepthShader depthshader;
    Vec4f screen_coords[3];
    for (int i=0; i<model->nfaces(); i++) {
        for (int j=0; j<3; j++) {
            screen_coords[j] = depthshader.vertex(i, j);
        }
        triangle(screen_coords, depthshader, depth, shadowbuffer);
    }
    depth.flip_vertically(); // to place the origin in the bottom left corner of the image
    depth.write_tga_file("depth.tga");
}

Matrix M = Viewport*Projection*ModelView;
```

我把摄像机放知道光源位置 (lookat(light_dir, center, up);) 然后进行渲染。注意我保留了 z-buffer，**shadowbuffer** 指针指向它。另外，很有用的一点是在最后一行，我保存了物体到屏幕空间的变换矩阵。下面是 shader 的运行结果：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/07-shadows/f743999b9d21aee9d0704c4036e18dce.png) 

第二遍渲染，自然就得用另一个 shader 了：

```c++
struct Shader : public IShader {
    mat<4,4,float> uniform_M;   //  Projection*ModelView
    mat<4,4,float> uniform_MIT; // (Projection*ModelView).invert_transpose()
    mat<4,4,float> uniform_Mshadow; // transform framebuffer screen coordinates to shadowbuffer screen coordinates
    mat<2,3,float> varying_uv;  // triangle uv coordinates, written by the vertex shader, read by the fragment shader
    mat<3,3,float> varying_tri; // triangle coordinates before Viewport transform, written by VS, read by FS

    Shader(Matrix M, Matrix MIT, Matrix MS) : uniform_M(M), uniform_MIT(MIT), uniform_Mshadow(MS), varying_uv(), varying_tri() {}

    virtual Vec4f vertex(int iface, int nthvert) {
        varying_uv.set_col(nthvert, model->uv(iface, nthvert));
        Vec4f gl_Vertex = Viewport*Projection*ModelView*embed<4>(model->vert(iface, nthvert));
        varying_tri.set_col(nthvert, proj<3>(gl_Vertex/gl_Vertex[3]));
        return gl_Vertex;
    }

    virtual bool fragment(Vec3f bar, TGAColor &color) {
        Vec4f sb_p = uniform_Mshadow*embed<4>(varying_tri*bar); // corresponding point in the shadow buffer
        sb_p = sb_p/sb_p[3];
        int idx = int(sb_p[0]) + int(sb_p[1])*width; // index in the shadowbuffer array
        float shadow = .3+.7*(shadowbuffer[idx]<sb_p[2]); 
        Vec2f uv = varying_uv*bar;                 // interpolate uv for the current pixel
        Vec3f n = proj<3>(uniform_MIT*embed<4>(model->normal(uv))).normalize(); // normal
        Vec3f l = proj<3>(uniform_M  *embed<4>(light_dir        )).normalize(); // light vector
        Vec3f r = (n*(n*l*2.f) - l).normalize();   // reflected light
        float spec = pow(std::max(r.z, 0.0f), model->specular(uv));
        float diff = std::max(0.f, n*l);
        TGAColor c = model->diffuse(uv);
        for (int i=0; i<3; i++) color[i] = std::min<float>(20 + c[i]*shadow*(1.2*diff + .6*spec), 255);
        return false;
    }
};
```

这个 shader 拷贝自上节的 [最终 shader](https://github.com/ssloy/tinyrenderer/wiki/Lesson-6:-Shaders-for-the-software-renderer#specular-mapping)，但有一点不同：我声明了一个常矩阵 `mat<4,4,float> uniform_Mshadow` ，这能当前片段的屏幕坐标，转换成 shaderbuffer 中的屏幕坐标！我待会儿再说这个矩阵是怎么算的，先看一下我是怎么使用的吧：

```c++
Vec4f sb_p = uniform_Mshadow*embed<4>(varying_tri*bar); // corresponding point in the shadow buffer
sb_p = sb_p/sb_p[3];
int idx = int(sb_p[0]) + int(sb_p[1])*width; // index in the shadowbuffer array
float shadow = .3+.7*(shadowbuffer[idx]<sb_p[2]);
```

varying_tri * bar 能得出当前我们在绘制的像素的屏幕坐标；我们把最后一个分量置 1 (回忆一下齐次坐标的部分)，然后用这个神奇的矩阵 uniform_Mshadow 变换它！boom！就得到了 shadow buffer 空间下的 xyz 坐标。现在，为确定当前像素是否点亮，只需将 z 坐标与当前 shadow buffer 中存储的值比较即可。

来看看我是怎么调用这个 shader 的：

```c++
Matrix M = Viewport*Projection*ModelView;

{ // rendering the frame buffer
    TGAImage frame(width, height, TGAImage::RGB);
    lookat(eye, center, up);
    viewport(width/8, height/8, width*3/4, height*3/4);
    projection(-1.f/(eye-center).norm());

    Shader shader(ModelView, (Projection*ModelView).invert_transpose(), M*(Viewport*Projection*ModelView).invert());
    Vec4f screen_coords[3];
    for (int i=0; i<model->nfaces(); i++) {
        for (int j=0; j<3; j++) {
            screen_coords[j] = shader.vertex(i, j);
        }
        triangle(screen_coords, shader, frame, zbuffer);
    }
    frame.flip_vertically(); // to place the origin in the bottom left corner of the image
    frame.write_tga_file("framebuffer.tga");
}
```

回忆一下，矩阵 M 是从物体空间 object space 转换到 shadow buffer 屏幕空间的变换矩阵。我们将摄像机放回原来的位置，重新计算视口矩阵 viewport matrix，投影矩阵 projection matrix 并调用第二个 shader。

我们知道 `Viewport*Projection*ModelView` 将物体坐标转换到 (帧缓冲 framebuffer 中的) 屏幕坐标。我们需要知道如何将 framebuffer 屏幕坐标转换到 shadow 屏幕坐标。这很简单：`(Viewport*Projection*ModelView).invert()` 能将 framebuffer 坐标转换成物体坐标，还有 `(Viewport*Projection*ModelView).invert()` 能将坐标在 framebuffer 和 shadowbuffer 之间转换。

一切都很顺利，但还有一个小问题：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/07-shadows/164be1dce9e980d47a90159103b954a3.png) 

注意到渲染出的丑陋阴影了吗？这个走样就是为人所知的深度碰撞 ([z-fighting](http://en.wikipedia.org/wiki/Z-fighting))，我们缓冲区的分辨率不足以存储非常精确的结果。如何解决？我喜欢暴力的方法：

```c++
float shadow = .3+.7*(shadowbuffer[idx]<sb_p[2]+43.34); // 加一个神奇的系数，能避免深度碰撞
```

我简单地将一个 z-buffer 相对另一个移动一点，就足以消除走样。是的，这会导致其他一些问题 (你能告诉我是哪个吗？)，但这些问题表现得不是很明显。最终的渲染结果，在摘要章节可以看到。

>   译者把它搬过来了 :-)
>
>   ![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/00-home/demon.png) 



# 家庭作业

## 阴影贴图 shadow maps

我更新了暗黑破坏神的模型，试着加一些阴影，渲染出来：

![img](https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/07-shadows/e3cd704925f52b5466ab3c4f9fbab899.png) 

## 发光效果

注意水晶和眼睛部分在发光，如何实现这个效果？































